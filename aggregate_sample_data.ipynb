{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Study Data Set from Example LMS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import ast\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_data/submission_comments.csv\n",
      "example_data/assignments.csv\n",
      "example_data/discussion_entry.csv\n",
      "example_data/course_section.csv\n",
      "example_data/submissions.csv\n",
      "example_data/survey_data.csv\n",
      "example_data/enrollments.csv\n",
      "example_data/.gitkeep\n",
      "example_data/assignments_overrides.csv\n"
     ]
    }
   ],
   "source": [
    "path = 'example_data'\n",
    "filelist = []\n",
    "\n",
    "for root, _, files in os.walk(path):\n",
    "    for file in files:\n",
    "        filelist.append(os.path.join(root, file))\n",
    "\n",
    "for f in filelist:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for f in filelist: \n",
    "    if \".csv\" not in f:\n",
    "        continue\n",
    "    entry_name = re.sub(r'\\.csv$', '', f.rsplit('/', 1)[-1])\n",
    "    d[entry_name] = pd.read_csv(f, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set and Variable Overview \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables of assignments\n",
      "['asn_due_at', 'asn_unlock_at', 'assignment_id', 'course_id', 'grading_type', 'workflow_state']\n",
      "\n",
      "Variables of assignments_overrides\n",
      "['assignment_id', 'due_at', 'unlock_at', 'updated_at']\n",
      "\n",
      "Variables of course_section\n",
      "['canvas_course_global_id', 'course_subject_name_number', 'section_num']\n",
      "\n",
      "Variables of discussion_entry\n",
      "['course_id', 'created_at', 'depth', 'discussion_entry_id', 'message_length', 'parent_discussion_entry_id', 'user_id']\n",
      "\n",
      "Variables of enrollments\n",
      "['course_id', 'enrollment_role_type', 'enrollment_state', 'enrollment_updated_at', 'user_id']\n",
      "\n",
      "Variables of submission_comments\n",
      "['author_id', 'course_id', 'message_size_bytes', 'submission_id']\n",
      "\n",
      "Variables of submissions\n",
      "['assignment_id', 'course_id', 'submission_id', 'submitted_at', 'user_id']\n",
      "\n",
      "Variables of survey_data\n",
      "['anon', 'avg_gpa', 'avg_grade', 'avg_major_gpa', 'course_name_number', 'credit_hours', 'grade_std', 'major', 'me', 'me_diff', 'me_importance', 'me_manage', 'n_prereqs', 'n_satisfied_prereqs_2021_Spring', 'n_satisfied_prereqs_all_past_semesters', 'percentage_of_non_letter_grades', 'percentage_of_pass_or_satisfactory_among_non_letter_grades', 'ps', 'ps_diff', 'ps_importance', 'ps_manage', 'secondary_section_number', 'section_num', 'tl1', 'tl1_diff', 'tl2', 'tl2_diff', 'tl_importance', 'tl_manage']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Each data frame is stored in one dictionary\n",
    "for key in sorted(d.keys()):\n",
    "    print('Variables of ' + key)\n",
    "    print(sorted(d[key].columns.tolist()))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Variable Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an overview of the features used in this study created from LMS records. Where the meaning of the variables can not be derived from their name, additional explanations are give. In addition, important definitions (e.g., what an original forum post is), how missing values were coded, as well as the expected associations of each feature with different course load types (i.e. time load: tl, mental effort: me, and psychological stress load: ps) are provided.\n",
    "\n",
    "As per default, variables are created through concatenating data from all available sections students enrolled in. This is done through functions iterating through each row in the survey data and looking up relevant data in the LMS records, then creating the following variables:\n",
    "\n",
    "*Note: Missing Values are represented by 0 and controlled for by binary variables representing whether a specific course used the forum, submission comments, assignment features in Canvas **at all**, with a 1 representing not used and a 0 representing used. Data can also later be omitted by referring to those binary variables prior to modelling. Some variables where 0s might naturally arise (e.g., dropout rate) might still contain NAs which will be cleaned in the R analysis script.*\n",
    "\n",
    "**Forum Posts**\n",
    "\n",
    "* n_original_forum_posts (made by students) - TL\n",
    "    * defined as depth 1 posts in LMS records\n",
    "    * with dropout version\n",
    "    * NA if there are no discussion entries. \n",
    "* original_post_avg_size_bytes (made by students) - TL, maybe ME\n",
    "    * with dropout version\n",
    "    * NA if there are no original posts by students, since we can not input 0 which would indicate small size.\n",
    "* original_forum_posts_per_student - TL\n",
    "    * with dropout version\n",
    "    * NA if no students participated in forum (can not divide by 0). \n",
    "* ta_teacher_posts_per_student - PS\n",
    "    * ignores dropout status of students. \n",
    "    * NA if no students participated in forum.\n",
    "* ta_teacher_avg_reply_time_minutes - PS\n",
    "    * with dropout version\n",
    "    * NA if no appropriate pair of student teacher interaction is available.\n",
    "* forum_reply_ratio (reply from either student^/TA/instructor) | ^including dropout students\n",
    "    * since posts having a reply influences the probability of whether a post received another reply, the reply can come from either students, dropout student, or instructors\n",
    "    * with dropout version\n",
    "    * NA if no relevant student (e.g., dropout student) particpated in forum.\n",
    "\n",
    "**Submissions and Submission Comments**\n",
    "\n",
    "* submission_comments_avg_size_bytes - maybe ME\n",
    "    * ignores user_role (i.e. student, instructor, ...) since these could not be matched to the relevant tables\n",
    "    * NA if there are no submission comments for a course/section numbers combination.\n",
    "* submission_comments_per_student - maybe ME\n",
    "    * ignores user_role (i.e. student, instructor, ...) since these could not be matched to the relevant tables\n",
    "    * NA if there were no submissions to assignments by students for a course/section numbers combination.\n",
    "* percent_submissions_submission_comments - PS\n",
    "    * ignores user_role (i.e. student, instructor, ...) since these could not be matched to the relevant tables\n",
    "    * NA if there were no relevant submissions to assignments by students in the course (i.e. can be 0).\n",
    "\n",
    "**Assignments**\n",
    "\n",
    "* assignment_spread (in SDs, with due date of assignment as reference) - PS\n",
    "    * subset of assignments which had due dates\n",
    "    * takes both graded and non-graded assignments\n",
    "    * NA if there were less than 2 assignments with due\n",
    "* parallel_assignments - PS\n",
    "    * subset of assignments which had due dates\n",
    "    * given a grace period of 1 day/3 days/1 day if ungraded & 3 if graded, how many pairs of timeframes overlapped?\n",
    "* n_course_assignments - TL\n",
    "    * based on all assignments (with or without due, unlock date)\n",
    "    * NA if there were no assignments (Canvas assignments were not used)\n",
    "* n_graded_assignments - TL \n",
    "    * based on all assignments (with or without due, unlock date)\n",
    "    * NA if there were no assignments (Canvas assignments were not used)\n",
    "* graded_assignments_week - TL\n",
    "    * subset of assignments which had due dates\n",
    "    * can be 0\n",
    "* max_graded_assignments_week (number of graded assignments during week with most assignments) - PS\n",
    "    * subset of assignments which had due dates\n",
    "    * can be 0\n",
    "* avg_submission_time_to_deadline_minutes (time between submission and deadline averaged over all submissions across courses) - PS\n",
    "    * with dropout version\n",
    "    * subset of courses which had due dates\n",
    "    * NA if either there were no assignments nor submissions\n",
    "* early_assignment_availability_ratio, ratio of frequency with which assignments are available within first 2 weeks of semester - PS, maybe ME\n",
    "    * subset of courses which had due dates **and** unlock dates\n",
    "    * Ratio of assignments unlocked before **two weeks** after semester start\n",
    "    * NA if no assignments were put into Canvas (i.e. functionality was not used)\n",
    "* avg_diff_available_due_assignments_minutes, assignment mean timeframe between availability and due date - PS\n",
    "    * subset of courses which had due dates **and** unlock dates\n",
    "    * NA if no assignments were put into Canvas (i.e. functionality was not used)\n",
    "\n",
    "\n",
    "**Misc**\n",
    "\n",
    "* dropout rates of course within 4 equally-sized quarters of instruction time - Maybe ME\n",
    "    * Based on dividing Spring 2021 semester ('2021-01-18 00:00:00.000', '2021-05-13 23:59:59.999') into 4 equally sized parts and counting how many students' last enrollment status changed to dropout during that timeframe for the **primary** section of the course.\n",
    "    * If no enrollment records are available for course name + primary section, return NA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reference table for adding user_roles to user_ids in the other tables\n",
    "# is created and joined to the relevant tables. In our actual records,\n",
    "# there were duplicate combinations of user x course x role which are\n",
    "# omitted here. This is not relevant for the example data we created.\n",
    "\n",
    "# Preselect variables\n",
    "temp = d['enrollments'][['course_id', 'user_id', 'enrollment_role_type']]\n",
    "\n",
    "# Filter Students, Teachers, TAs\n",
    "temp = temp[temp['enrollment_role_type'].isin(['StudentEnrollment', 'TeacherEnrollment', 'TaEnrollment'])]\n",
    "\n",
    "# Make strings cleaner\n",
    "temp['enrollment_role_type'] = temp['enrollment_role_type'].str.replace('Enrollment', '') \n",
    "\n",
    "# Sort data frame such that Teacher and TA enrollment appear first\n",
    "temp = temp.sort_values(by='enrollment_role_type', ascending=False)\n",
    "\n",
    "# Drop duplicates such that first unique combination with Teacher or TA is kept\n",
    "temp = temp.drop_duplicates(subset=['course_id', 'user_id'], keep='first', inplace=False)\n",
    "\n",
    "user_role_reference_table = temp\n",
    "\n",
    "# Simplify variable name\n",
    "user_role_reference_table = user_role_reference_table.rename({'enrollment_role_type': 'user_role'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left join user role to table `discussion entry` and `submissions`, check that no duplicate rows emerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Discussion Entry Table')\n",
    "print(d['discussion_entry'].shape)\n",
    "d['discussion_entry'] = d['discussion_entry'].merge(user_role_reference_table, on=['course_id', 'user_id'], how='left')\n",
    "print(d['discussion_entry'].shape)\n",
    "print(round(sum(pd.isna(d['discussion_entry'].user_role)) / d['discussion_entry'].shape[0], 4) * 100, '% missing user roles')\n",
    "print('')\n",
    "print('Submissions Table')\n",
    "print(d['submissions'].shape)\n",
    "d['submissions'] = d['submissions'].merge(user_role_reference_table, on=['course_id', 'user_id'], how='left')\n",
    "print(d['submissions'].shape)\n",
    "print(round(sum(pd.isna(d['submissions'].user_role)) / d['submissions'].shape[0], 4) * 100, '% missing user roles')\n",
    "print('')\n",
    "print('Submission Comments Table')\n",
    "print(d['submission_comments'].shape)\n",
    "d['submission_comments'] = d['submission_comments'].rename({'author_id': 'user_id'}, axis=1) # fix user id var name\n",
    "d['submission_comments']['user_id'] = d['submission_comments'].user_id.fillna(0).astype(int) # fix encoding for correct joining\n",
    "d['submission_comments'] = d['submission_comments'].merge(user_role_reference_table, on=['course_id', 'user_id'], how='left')\n",
    "print(d['submission_comments'].shape)\n",
    "print(round(sum(pd.isna(d['submission_comments'].user_role)) / d['submission_comments'].shape[0], 4) * 100, '% missing user roles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and join variable whether student is dropout or not: 1: dropout, 0: normal, -1: not student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take most recent enrollment state of each user in each course\n",
    "temp = d['enrollments'][['course_id', 'user_id', 'enrollment_updated_at', 'enrollment_state']]\n",
    "temp = temp.sort_values(by=['enrollment_updated_at', 'course_id', 'user_id'], ascending=False)\n",
    "temp = temp.drop_duplicates(subset=['course_id', 'user_id'], keep='first', inplace=False)\n",
    "enrollment_status = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join last updated status including timestamp to tables\n",
    "print('Discussion Entry Table')\n",
    "print(d['discussion_entry'].shape)\n",
    "d['discussion_entry'] = d['discussion_entry'].merge(enrollment_status, on=['course_id', 'user_id'], how='left')\n",
    "print(d['discussion_entry'].shape)\n",
    "print('')\n",
    "print('Submissions Table')\n",
    "print(d['submissions'].shape)\n",
    "d['submissions'] = d['submissions'].merge(enrollment_status, on=['course_id', 'user_id'], how='left')\n",
    "print(d['submissions'].shape)\n",
    "print('')\n",
    "print('Submission Comments Table')\n",
    "print(d['submission_comments'].shape)\n",
    "d['submission_comments'] = d['submission_comments'].merge(enrollment_status, on=['course_id', 'user_id'], how='left')\n",
    "print(d['submission_comments'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create relevant variables\n",
    "# A: If user is student and last updated enrollment status is deleted, then assign dropout status\n",
    "#    If user is not student, assign -1, if user is student and not a dropout, assign 0 (active or completed)\n",
    "# B: If user is a dropout student, return last updated enrollment status as time of dropout, else assign NA\n",
    "\n",
    "def student_dropout_conditions(row):\n",
    "    if row['user_role'] != 'Student':\n",
    "        return -1\n",
    "    else:\n",
    "        if row['enrollment_state'] in ['active', 'completed']:\n",
    "            return 0\n",
    "        elif row['enrollment_state'] == 'deleted':\n",
    "            return 1\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "def dropout_at_conditions(row):\n",
    "    if row['is_student_dropout'] != 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return row['enrollment_updated_at']\n",
    "\n",
    "d['discussion_entry']['is_student_dropout'] = d['discussion_entry'].apply(student_dropout_conditions, axis=1)\n",
    "d['submissions']['is_student_dropout'] = d['submissions'].apply(student_dropout_conditions, axis=1)\n",
    "d['submission_comments']['is_student_dropout'] = d['submission_comments'].apply(student_dropout_conditions, axis=1)\n",
    "\n",
    "d['discussion_entry']['dropout_at'] = d['discussion_entry'].apply(dropout_at_conditions, axis=1)\n",
    "d['submissions']['dropout_at'] = d['submissions'].apply(dropout_at_conditions, axis=1)\n",
    "d['submission_comments']['dropout_at'] = d['submission_comments'].apply(dropout_at_conditions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments Subsets for Feature Creation\n",
    "\n",
    "1. Sample all assignments which are published in assignments table\n",
    "    * Overwrite to assignments table\n",
    "    * Base number of assignments and related variables on these assignments\n",
    "2. Filter all assignments with updated deadlines\n",
    "    * Save to separate data frame (`assignments_with_due`)\n",
    "    * Base parallel assignments and related variables on these variables\n",
    "3. Filter all assignments that have an updated unlock date (we do not know exactly when assignments were available for students for the remaining assignments\n",
    "    * Save to separate data frame (`assignments_with_due-unlock`)\n",
    "    * Base assignments availability variables on these assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update due date in `assignment` table through `assignment_overrides` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_due_dates = d['assignments_overrides'].sort_values(by=['updated_at'], ascending=False)  # sort by most recent\n",
    "updated_due_dates = updated_due_dates.loc[updated_due_dates['due_at'].notnull(), ['assignment_id', 'due_at']]\n",
    "updated_due_dates.assignment_id = updated_due_dates.assignment_id.fillna(0).astype(int)\n",
    "updated_due_dates = updated_due_dates.drop_duplicates(subset = 'assignment_id', keep = 'first') # keep most recent\n",
    "\n",
    "# Join most recent entries to main table\n",
    "d['assignments'] = pd.merge(d['assignments'], updated_due_dates, on='assignment_id', how='left')\n",
    "\n",
    "# Take most recent due_at if available, else take asn_due_at from original table\n",
    "d['assignments']['due_at_correct'] = d['assignments'][['asn_due_at', 'due_at']].apply(lambda x: x['asn_due_at'] if pd.isnull(x['due_at']) else x['due_at'], axis=1)\n",
    "\n",
    "# there was one erreneuous row with the year 4444\n",
    "d['assignments'] = d['assignments'][d['assignments']['due_at_correct']!='4444-04-05 06:59:59']\n",
    "\n",
    "d['assignments']['due_at_correct'] = pd.to_datetime(d['assignments']['due_at_correct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update unlock date in `assignment` table through `assignment_overrides` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "\n",
    "updated_unlock_dates = d['assignments_overrides'].sort_values(by=['updated_at'], ascending=False)\n",
    "updated_unlock_dates = updated_unlock_dates.loc[updated_unlock_dates['unlock_at'].notnull(), ['assignment_id', 'unlock_at']]\n",
    "updated_unlock_dates.assignment_id = updated_unlock_dates.assignment_id.fillna(0).astype(int)\n",
    "updated_unlock_dates = updated_unlock_dates.drop_duplicates(subset = 'assignment_id', keep = 'first')\n",
    "\n",
    "d['assignments'] = pd.merge(d['assignments'], updated_unlock_dates, on='assignment_id', how='left')\n",
    "d['assignments']['unlock_at_updated'] = d['assignments'][['asn_unlock_at', 'unlock_at']].apply(lambda x: x['asn_unlock_at'] if pd.isnull(x['unlock_at']) else x['unlock_at'], axis=1)\n",
    "\n",
    "# there was one erreneuous row with the year 3333\n",
    "d['assignments'] = d['assignments'][d['assignments']['unlock_at_updated']!='3333-03-03 08:00:00']\n",
    "\n",
    "d['assignments']['unlock_at_updated'] = pd.to_datetime(d['assignments']['unlock_at_updated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preselect assignments\n",
    "\n",
    "* Workflow state must be published\n",
    "* Assignments should have at least one submission by students\n",
    "* Assigns should not have a due date before the beginning of the the Spring 2021 semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of assignments that had an active workflow state in assignments_000 table: 32.13 %\n"
     ]
    }
   ],
   "source": [
    "# Published workflow state\n",
    "\n",
    "print('% of assignments that had an active workflow state in assignments_000 table:',\n",
    "    '%.2f' % (round(d['assignments'][d['assignments'].workflow_state == 'published'].shape[0]/\n",
    "        d['assignments'].shape[0], 4)* 100), '%'\n",
    ")\n",
    "\n",
    "d['assignments'] = d['assignments'][d['assignments'].workflow_state == 'published']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We confirmed that 1.04 % of published assignments had submissions by students\n"
     ]
    }
   ],
   "source": [
    "# Assignments with at least 1 submission by students\n",
    "\n",
    "assignment_ids_with_submissions = set(d['submissions'][\n",
    "                                (d['submissions'].user_role == 'Student') & \n",
    "                                (d['submissions'].assignment_id.isin(d['assignments'].assignment_id))]\\\n",
    "                                      .assignment_id)\n",
    "\n",
    "n_assignments_with_submissions = len(assignment_ids_with_submissions)\n",
    "n_assignments = len(pd.unique(d['assignments'].assignment_id))\n",
    "\n",
    "d['assignments'] = d['assignments'][d['assignments'].assignment_id.isin(assignment_ids_with_submissions)]\n",
    "\n",
    "print('We confirmed that', \\\n",
    "      '%.2f' % (round(n_assignments_with_submissions/n_assignments, 4)*100), \\\n",
    "      '% of published assignments had submissions by students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00 % of published assignments with at least 1 submission had due dates on or after the start of the semester\n"
     ]
    }
   ],
   "source": [
    "# Filter out assignments with due dates before semester start Spring 2021\n",
    "\n",
    "semester_start = pd.to_datetime('2021-01-18 00:00:00.000')\n",
    "\n",
    "print(\n",
    "    '%.2f' % (round(d['assignments'].loc[~(\n",
    "    (d['assignments'].due_at_correct.notna()) &\n",
    "    (d['assignments'].due_at_correct < semester_start)\n",
    "    ),].shape[0] / d['assignments'].shape[0], 4)*100), \n",
    "    '% of published assignments with at least 1 submission had due dates on or after the start of the semester'\n",
    ")\n",
    "\n",
    "d['assignments'] = d['assignments'].loc[~(\n",
    "    (d['assignments'].due_at_correct.notna()) &\n",
    "    (d['assignments'].due_at_correct < semester_start)\n",
    "),]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 % of published assignments did not have a due date (after updating most recent non-empty value from overrides table)\n"
     ]
    }
   ],
   "source": [
    "## Apply Filtering for Subset Creation and Print Omission Stats\n",
    "\n",
    "print(\n",
    "'%.2f' % \n",
    "(round(sum(d['assignments'].due_at_correct.isna())/len(d['assignments'].due_at_correct), 4) * 100),\n",
    "    '% of published assignments did not have a due date (after updating most recent non-empty value from overrides table)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['assignments_with_due'] = d['assignments'][d['assignments'].due_at_correct.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 % of those assignments did not have an unlock date (after updating most recent non-empty value from overrides table)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "'%.2f' % \n",
    "(round(sum(d['assignments_with_due'].unlock_at_updated.isna())/len(d['assignments_with_due'].unlock_at_updated), 4) * 100),\n",
    "    '% of those assignments did not have an unlock date (after updating most recent non-empty value from overrides table)'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['assignments_with_due-unlock'] = d['assignments_with_due'][d['assignments_with_due'].unlock_at_updated.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in and Cleaning Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon</th>\n",
       "      <th>course_name_number</th>\n",
       "      <th>section_num</th>\n",
       "      <th>secondary_section_number</th>\n",
       "      <th>n_prereqs</th>\n",
       "      <th>n_satisfied_prereqs_2021_Spring</th>\n",
       "      <th>n_satisfied_prereqs_all_past_semesters</th>\n",
       "      <th>credit_hours</th>\n",
       "      <th>avg_grade</th>\n",
       "      <th>grade_std</th>\n",
       "      <th>percentage_of_non_letter_grades</th>\n",
       "      <th>percentage_of_pass_or_satisfactory_among_non_letter_grades</th>\n",
       "      <th>tl_importance</th>\n",
       "      <th>me_importance</th>\n",
       "      <th>ps_importance</th>\n",
       "      <th>major</th>\n",
       "      <th>avg_gpa</th>\n",
       "      <th>avg_major_gpa</th>\n",
       "      <th>tl1</th>\n",
       "      <th>tl2</th>\n",
       "      <th>tl_manage</th>\n",
       "      <th>me</th>\n",
       "      <th>me_manage</th>\n",
       "      <th>ps</th>\n",
       "      <th>ps_manage</th>\n",
       "      <th>tl1_diff</th>\n",
       "      <th>tl2_diff</th>\n",
       "      <th>me_diff</th>\n",
       "      <th>ps_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Political Science 103</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.484848</td>\n",
       "      <td>1.232323</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Business Administration</td>\n",
       "      <td>3.939394</td>\n",
       "      <td>2.303030</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Political Science 103</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.878788</td>\n",
       "      <td>1.060606</td>\n",
       "      <td>0.929293</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>L&amp;S Data Science</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>3.696970</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Physics 112</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.121212</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>L&amp;S Data Science</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>1.515152</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Sociology 1</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.575758</td>\n",
       "      <td>1.050505</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.747475</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>L&amp;S Data Science</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>2.454545</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-5</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Political Science 103</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.424242</td>\n",
       "      <td>1.161616</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>L&amp;S Data Science</td>\n",
       "      <td>1.606061</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>249</td>\n",
       "      <td>Sociology 1</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 2]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.969697</td>\n",
       "      <td>1.121212</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>L&amp;S Data Science</td>\n",
       "      <td>3.848485</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>249</td>\n",
       "      <td>Physics 112</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>1.808081</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>L&amp;S Data Science</td>\n",
       "      <td>1.121212</td>\n",
       "      <td>1.969697</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>249</td>\n",
       "      <td>Sociology 1</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>L&amp;S Data Science</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>249</td>\n",
       "      <td>Political Science 103</td>\n",
       "      <td>3</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>1.050505</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Business Administration</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>2.454545</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>249</td>\n",
       "      <td>Political Science 103</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.878788</td>\n",
       "      <td>1.030303</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>L&amp;S Data Science</td>\n",
       "      <td>1.393939</td>\n",
       "      <td>3.818182</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anon     course_name_number  section_num secondary_section_number  \\\n",
       "0        0  Political Science 103            3                   [2, 3]   \n",
       "1        0  Political Science 103            3                   [2, 3]   \n",
       "2        0            Physics 112            3                   [3, 2]   \n",
       "3        0            Sociology 1            2                   [1, 1]   \n",
       "4        0  Political Science 103            2                   [3, 1]   \n",
       "...    ...                    ...          ...                      ...   \n",
       "1245   249            Sociology 1            2                   [3, 2]   \n",
       "1246   249            Physics 112            2                   [2, 3]   \n",
       "1247   249            Sociology 1            2                   [1, 1]   \n",
       "1248   249  Political Science 103            3                   [3, 1]   \n",
       "1249   249  Political Science 103            2                   [3, 3]   \n",
       "\n",
       "      n_prereqs  n_satisfied_prereqs_2021_Spring  \\\n",
       "0             5                                0   \n",
       "1             4                                3   \n",
       "2             0                                5   \n",
       "3             1                                2   \n",
       "4             0                                4   \n",
       "...         ...                              ...   \n",
       "1245          5                                0   \n",
       "1246          1                                4   \n",
       "1247          2                                0   \n",
       "1248          5                                3   \n",
       "1249          2                                1   \n",
       "\n",
       "      n_satisfied_prereqs_all_past_semesters  credit_hours  avg_grade  \\\n",
       "0                                          2             4   2.484848   \n",
       "1                                          0             3   3.878788   \n",
       "2                                          5             3   3.121212   \n",
       "3                                          3             4   2.575758   \n",
       "4                                          1             3   3.424242   \n",
       "...                                      ...           ...        ...   \n",
       "1245                                       0             2   3.969697   \n",
       "1246                                       2             3   3.272727   \n",
       "1247                                       5             1   3.333333   \n",
       "1248                                       4             1   1.181818   \n",
       "1249                                       3             4   3.878788   \n",
       "\n",
       "      grade_std  percentage_of_non_letter_grades  \\\n",
       "0      1.232323                         0.969697   \n",
       "1      1.060606                         0.929293   \n",
       "2      1.555556                         0.636364   \n",
       "3      1.050505                         0.777778   \n",
       "4      1.161616                         0.282828   \n",
       "...         ...                              ...   \n",
       "1245   1.121212                         0.202020   \n",
       "1246   1.808081                         0.828283   \n",
       "1247   1.363636                         0.464646   \n",
       "1248   1.050505                         0.232323   \n",
       "1249   1.030303                         0.222222   \n",
       "\n",
       "      percentage_of_pass_or_satisfactory_among_non_letter_grades  \\\n",
       "0                                              0.383838            \n",
       "1                                              0.474747            \n",
       "2                                              0.333333            \n",
       "3                                              0.747475            \n",
       "4                                              0.141414            \n",
       "...                                                 ...            \n",
       "1245                                           0.848485            \n",
       "1246                                           0.040404            \n",
       "1247                                           0.474747            \n",
       "1248                                           0.121212            \n",
       "1249                                           0.717172            \n",
       "\n",
       "      tl_importance  me_importance  ps_importance                    major  \\\n",
       "0                 3              2              4  Business Administration   \n",
       "1                 4              3              3         L&S Data Science   \n",
       "2                 3              2              1         L&S Data Science   \n",
       "3                 3              2              1         L&S Data Science   \n",
       "4                 4              4              2         L&S Data Science   \n",
       "...             ...            ...            ...                      ...   \n",
       "1245              2              5              2         L&S Data Science   \n",
       "1246              5              2              2         L&S Data Science   \n",
       "1247              4              5              5         L&S Data Science   \n",
       "1248              5              4              5  Business Administration   \n",
       "1249              4              5              1         L&S Data Science   \n",
       "\n",
       "       avg_gpa  avg_major_gpa  tl1  tl2  tl_manage  me  me_manage  ps  \\\n",
       "0     3.939394       2.303030    5    3          4   4          2   4   \n",
       "1     3.090909       3.696970    4    2          4   1          5   5   \n",
       "2     1.454545       1.515152    6    5          3   5          2   2   \n",
       "3     3.636364       2.454545    5    5          5   5          2   1   \n",
       "4     1.606061       1.363636    3    5          1   4          4   3   \n",
       "...        ...            ...  ...  ...        ...  ..        ...  ..   \n",
       "1245  3.848485       3.727273    2    3          3   5          2   2   \n",
       "1246  1.121212       1.969697    6    5          3   5          1   3   \n",
       "1247  2.666667       2.666667    3    1          1   3          3   1   \n",
       "1248  1.090909       2.454545    3    3          3   5          4   1   \n",
       "1249  1.393939       3.818182    3    5          2   2          3   3   \n",
       "\n",
       "      ps_manage  tl1_diff  tl2_diff  me_diff  ps_diff  \n",
       "0             2        -1        -4       -1       -4  \n",
       "1             2        -2        -4        2       -2  \n",
       "2             3         0        -4       -3       -1  \n",
       "3             4        -5         4       -4        2  \n",
       "4             2         0         4       -4        2  \n",
       "...         ...       ...       ...      ...      ...  \n",
       "1245          2        -4         2       -1        4  \n",
       "1246          4        -2         1        1        4  \n",
       "1247          1        -3         2       -2        0  \n",
       "1248          2        -3         0       -2        4  \n",
       "1249          2         0         4       -3       -3  \n",
       "\n",
       "[1250 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['survey_data'] # This is synthetic, randomized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey_course_reference will be later used for data set filtering during variable creation\n",
    "survey_course_reference = d['survey_data'][['course_name_number', 'section_num', 'secondary_section_number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A hand-coded list of ANON UNIVERSITY Courses representing\n",
    "# they are STEM courses or not. Coding based on:\n",
    "# https://www.ice.gov/sites/default/files/documents/stem-list.pdf\n",
    "\n",
    "d_stem_courses = {\n",
    "\"American Studies 101\": False,\n",
    "\"American Studies C172\": False,\n",
    "\"Anthropology 115\": False,\n",
    "\"Anthropology 121AC\": False,\n",
    "\"Anthropology 141\": False,\n",
    "\"Anthropology 160AC\": False,\n",
    "\"Anthropology 3AC\": False,\n",
    "\"Architecture 11B\": False,  # only lists Naval Architecture and Marine Engineering.\n",
    "\"Architecture 170B\": False,  # only lists Naval Architecture and Marine Engineering.\n",
    "\"Architecture 198BC\": False,  # only lists Naval Architecture and Marine Engineering.\n",
    "\"Asian Am & Asn Diaspora Stds 121\": False,\n",
    "\"Asian Am & Asn Diaspora Stds 132AC\": False,\n",
    "\"Asian Am & Asn Diaspora Stds 171\": False,\n",
    "\"Asian Am & Asn Diaspora Stds 20A\": False,\n",
    "\"Astronomy 84\": True,\n",
    "\"Astronomy C12\": True,\n",
    "\"Bioengineering 100\": True,\n",
    "\"Bioengineering 104\": True,\n",
    "\"Bioengineering 11\": True,\n",
    "\"Bioengineering 110\": True,\n",
    "\"Bioengineering 153\": True,\n",
    "\"Bioengineering 25\": True,\n",
    "\"Bioengineering 98\": True,\n",
    "\"Biology 1A\": True,\n",
    "\"Biology 1AL\": True,\n",
    "\"Biology 1B\": True,\n",
    "\"Business Admin-Undergrad 10\": False,   # list includes business, but only business statistics and not administration\n",
    "\"Business Admin-Undergrad 102B\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 103\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 105\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 106\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 131\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 135\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 141\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 147\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 169\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 192T\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 194\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Business Admin-Undergrad 198\": False,   # list includes business, but only business statistics and not administration,\n",
    "\"Celtic Studies R1B\": False,\n",
    "\"Chemical Engineering 141\": True,\n",
    "\"Chemical Engineering 150A\": True,\n",
    "\"Chemical Engineering 98\": True,\n",
    "\"Chemistry 12B\": True,\n",
    "\"Chemistry 1A\": True,\n",
    "\"Chemistry 1AL\": True,\n",
    "\"Chemistry 1B\": True,\n",
    "\"Chemistry 3A\": True,\n",
    "\"Chemistry 3AL\": True,\n",
    "\"Chemistry 3B\": True,\n",
    "\"Chemistry 3BL\": True,\n",
    "\"Chemistry 98\": True,\n",
    "\"Chinese 10Y\": False,\n",
    "\"Chinese 1A\": False,\n",
    "\"Civil & Environmental Eng 105\": True,\n",
    "\"Civil & Environmental Eng 107\": True,\n",
    "\"Civil & Environmental Eng 11\": True,\n",
    "\"Civil & Environmental Eng 113\": True,\n",
    "\"Civil & Environmental Eng 123\": True,\n",
    "\"Civil & Environmental Eng 155\": True,\n",
    "\"Civil & Environmental Eng 166\": True,\n",
    "\"Civil & Environmental Eng 175\": True,\n",
    "\"Civil & Environmental Eng 198\": True,\n",
    "\"Civil & Environmental Eng 199\": True,\n",
    "\"Civil & Environmental Eng C88\": True,\n",
    "\"Classics 10B\": False,\n",
    "\"Classics 130E\": False,\n",
    "\"Classics 28\": False,\n",
    "\"Cognitive Science 1\": True,\n",
    "\"Cognitive Science 131\": True,\n",
    "\"Cognitive Science 190\": True,\n",
    "\"College Writing Programs R1A\": False,\n",
    "\"College Writing Programs R4B\": False,\n",
    "\"Computer Science 10\": True,\n",
    "\"Computer Science 161\": True,\n",
    "\"Computer Science 162\": True,\n",
    "\"Computer Science 170\": True,\n",
    "\"Computer Science 188\": True,\n",
    "\"Computer Science 189\": True,\n",
    "\"Computer Science 194\": True,\n",
    "\"Computer Science 195\": True,\n",
    "\"Computer Science 197\": True,\n",
    "\"Computer Science 198\": True,\n",
    "\"Computer Science 370\": True,\n",
    "\"Computer Science 47B\": True,\n",
    "\"Computer Science 61A\": True,\n",
    "\"Computer Science 61B\": True,\n",
    "\"Computer Science 61C\": True,\n",
    "\"Computer Science 70\": True,\n",
    "\"Computer Science 88\": True,\n",
    "\"Computer Science W182\": True,\n",
    "\"Computer Science W186\": True,\n",
    "\"Data Science, Undergraduate 198\": True,   # data science is usually listed as 11.0401 Information Science/Studies.\n",
    "\"Data Science, Undergraduate C100\": True,\n",
    "\"Data Science, Undergraduate C104\": True,\n",
    "\"Data Science, Undergraduate C8\": True,\n",
    "\"Demography C175\": False,\n",
    "\"Design Innovation 10\": False,\n",
    "\"Design Innovation 15\": False,\n",
    "\"Design Innovation 198\": False,\n",
    "\"Design Innovation 98\": False,\n",
    "\"Dutch 171AC\": False,\n",
    "\"Earth & Planetary Science C12\": True,\n",
    "\"Economics 1\": False,     # list only lists econometrics/quantitative economics\n",
    "\"Economics 100A\": False,\n",
    "\"Economics 100B\": False,\n",
    "\"Economics 101A\": False,\n",
    "\"Economics 115\": False,\n",
    "\"Economics 157\": False,\n",
    "\"Economics 172\": False,\n",
    "\"Education 130\": False,\n",
    "\"Education 197\": False,\n",
    "\"Electrical Eng & Computer Sci 126\": True,\n",
    "\"Electrical Eng & Computer Sci 127\": True,\n",
    "\"Electrical Eng & Computer Sci 16A\": True,\n",
    "\"Electrical Eng & Computer Sci 16B\": True,\n",
    "\"Energy and Resources 98\": True,\n",
    "\"Engineering 125\": True,\n",
    "\"Engineering 26\": True,\n",
    "\"Engineering 29\": True,\n",
    "\"English 110\": False,\n",
    "\"English 170\": False,\n",
    "\"English 24\": False,\n",
    "\"English 43B\": False,\n",
    "\"English 45C\": False,\n",
    "\"English R1B\": False,\n",
    "\"Env Sci, Policy, & Mgmt 114\": True,  # Environmental Science is Listed\n",
    "\"Env Sci, Policy, & Mgmt 131\": True,\n",
    "\"Env Sci, Policy, & Mgmt 152\": True,\n",
    "\"Env Sci, Policy, & Mgmt 40\": True,\n",
    "\"Env Sci, Policy, & Mgmt 50AC\": True,\n",
    "\"Env Sci, Policy, & Mgmt 98\": True,\n",
    "\"Env Sci, Policy, & Mgmt 98BC\": True,\n",
    "\"Env Sci, Policy, & Mgmt C167\": True,\n",
    "\"Environ Econ & Policy C101\": False,\n",
    "\"Environmental Design 100\": False,\n",
    "\"Ethnic Studies 101A\": False,\n",
    "\"Ethnic Studies 190\": False,\n",
    "\"Ethnic Studies 197\": False,\n",
    "\"Film 171\": False,\n",
    "\"Film R1B\": False,\n",
    "\"French 1\": False,\n",
    "\"French 2\": False,\n",
    "\"Gender & Womens Studies 100AC\": False,\n",
    "\"Gender & Womens Studies 139\": False,\n",
    "\"Geography 130\": False, # only lists Geographic Information Science and Cartography.\n",
    "\"Geography 70AC\": False,\n",
    "\"Global Poverty & Practice 105\": False,\n",
    "\"Global Studies 110Q\": False,\n",
    "\"Global Studies 173\": False,\n",
    "\"Global Studies C10A\": False,\n",
    "\"History 100M\": False,\n",
    "\"History 109C\": False,\n",
    "\"History 160\": False,\n",
    "\"History 190\": False,\n",
    "\"History 6B\": False,\n",
    "\"History C139C\": False,\n",
    "\"History R1B\": False,\n",
    "\"History of Art 190F\": False,\n",
    "\"Industrial Eng & Ops Rsch 135\": True,\n",
    "\"Industrial Eng & Ops Rsch 162\": True,\n",
    "\"Industrial Eng & Ops Rsch 165\": True,\n",
    "\"Industrial Eng & Ops Rsch 166\": True,\n",
    "\"Industrial Eng & Ops Rsch 170\": True,\n",
    "\"Industrial Eng & Ops Rsch 173\": True,\n",
    "\"Industrial Eng & Ops Rsch 185\": True,\n",
    "\"Industrial Eng & Ops Rsch 186\": True,\n",
    "\"Industrial Eng & Ops Rsch 190E\": True,\n",
    "\"Industrial Eng & Ops Rsch 195\": True,\n",
    "\"Industrial Eng & Ops Rsch 221\": True,\n",
    "\"Industrial Eng & Ops Rsch 95\": True,\n",
    "\"Information C265\": True, # iSchool course on interface design\n",
    "\"Integrative Biology 169\": True,\n",
    "\"Integrative Biology 192\": True,\n",
    "\"Integrative Biology 198\": True,\n",
    "\"Integrative Biology 77B\": True,\n",
    "\"Integrative Biology 84\": True,\n",
    "\"Integrative Biology 98\": True,\n",
    "\"Integrative Biology 98BC\": True,\n",
    "\"Integrative Biology C32\": True,\n",
    "\"Interdisciplinary Studies 100J\": False, # \"The Social Life of Computing\", historical and ethnographic methods\n",
    "\"Italian Studies R5B\": False,\n",
    "\"Korean 10B\": False,\n",
    "\"Korean 112\": False,\n",
    "\"LGBT Studies 145\": False,\n",
    "\"Landscape Arch & Env Plan 1\": False, # only lists Naval Architecture and Marine Engineering.\n",
    "\"Latin 100\": False,\n",
    "\"Letters & Science 22\": False,  # interdisciplinary studies\n",
    "\"Letters & Science 25\": False,  # interdisciplinary studies\n",
    "\"Linguistics 100\": False, # only lists Cognitive Psychology and Psycholinguistics.\n",
    "\"Linguistics 115\": False,\n",
    "\"Linguistics 47\": False,\n",
    "\"Linguistics C105\": False,\n",
    "\"Materials Science & Eng 45\": True,\n",
    "\"Mathematics 104\": True,\n",
    "\"Mathematics 10B\": True,\n",
    "\"Mathematics 110\": True,\n",
    "\"Mathematics 124\": True,\n",
    "\"Mathematics 128A\": True,\n",
    "\"Mathematics 152\": True,\n",
    "\"Mathematics 160\": True,\n",
    "\"Mathematics 16B\": True,\n",
    "\"Mathematics 1A\": True,\n",
    "\"Mathematics 1B\": True,\n",
    "\"Mathematics 53\": True,\n",
    "\"Mathematics 1B\": True,\n",
    "\"Mathematics 53\": True,\n",
    "\"Mathematics 54\": True,\n",
    "\"Mathematics 55\": True,\n",
    "\"Mathematics 98\": True,\n",
    "\"Mathematics 98BC\": True,\n",
    "\"Mechanical Engineering 104\": True,\n",
    "\"Mechanical Engineering 40\": True,\n",
    "\"Mechanical Engineering C85\": True,\n",
    "\"Media Studies 111\": False,\n",
    "\"Media Studies 113\": False,\n",
    "\"Military Affairs 180\": False,  # must be applied military technology to be STE\n",
    "\"Molecular & Cell Biology 100B\": True,\n",
    "\"Molecular & Cell Biology 102\": True,\n",
    "\"Molecular & Cell Biology 140\": True,\n",
    "\"Molecular & Cell Biology 140L\": True,\n",
    "\"Molecular & Cell Biology 198\": True,\n",
    "\"Molecular & Cell Biology 199\": True,\n",
    "\"Molecular & Cell Biology 38\": True,\n",
    "\"Molecular & Cell Biology 50\": True,\n",
    "\"Molecular & Cell Biology 90E\": True,\n",
    "\"Molecular & Cell Biology C61\": True,\n",
    "\"Molecular & Cell Biology C95B\": True,\n",
    "\"Music 128\": False,\n",
    "\"Music 159\": False,\n",
    "\"Music 168B\": False,\n",
    "\"Music 168C\": False,\n",
    "\"Music 168CS\": False,\n",
    "\"Music 170\": False,\n",
    "\"Music 20A\": False,\n",
    "\"Music 25\": False,\n",
    "\"Music 27\": False,\n",
    "\"Music 45M\": False,\n",
    "\"Music 52A\": False,\n",
    "\"Music 52B\": False,\n",
    "\"Music 53A\": False,\n",
    "\"Music 53B\": False,\n",
    "\"Music 80\": False,\n",
    "\"Music R1B\": False,\n",
    "\"Near Eastern Studies 10\": False,\n",
    "\"Near Eastern Studies 18\": False,\n",
    "\"Nuclear Engineering 155\": True,\n",
    "\"Nuclear Engineering 162\": True,\n",
    "\"Nutritional Science & Tox 10S\": True,\n",
    "\"Nutritional Science & Tox 11\": True,\n",
    "\"Nutritional Science & Tox 160\": True,\n",
    "\"Nutritional Science & Tox 170\": True,\n",
    "\"Nutritional Science & Tox 190\": True,\n",
    "\"Nutritional Science & Tox 198\": True,\n",
    "\"Nutritional Science & Tox 20\": True,\n",
    "\"Philosophy 104\": False,\n",
    "\"Philosophy 121\": False,\n",
    "\"Philosophy 12A\": False,\n",
    "\"Philosophy 135\": False,                                                                                                                                                                                       \n",
    "\"Philosophy 161\": False,\n",
    "\"Philosophy 25B\": False,\n",
    "\"Philosophy 3\": False,\n",
    "\"Physical Education 1\": False,\n",
    "\"Physics 112\": True,\n",
    "\"Physics 137A\": True,\n",
    "\"Physics 137B\": True,\n",
    "\"Physics 7A\": True,\n",
    "\"Physics 7B\": True,\n",
    "\"Physics 8A\": True,\n",
    "\"Physics 8B\": True,\n",
    "\"Physics C21\": True,\n",
    "\"Plant & Microbial Biology 122\": True,\n",
    "\"Plant & Microbial Biology 40\": True,\n",
    "\"Plant & Microbial Biology C112L\": True,\n",
    "\"Political Science 103\": False,\n",
    "\"Political Science 111AC\": False,\n",
    "\"Political Science 112C\": False,\n",
    "\"Political Science 146A\": False,\n",
    "\"Political Science 148A\": False,\n",
    "\"Political Science 149E\": False,\n",
    "\"Political Science 149P\": False,\n",
    "\"Political Science 179\": False,\n",
    "\"Political Science 197\": False,\n",
    "\"Political Science 2\": False,\n",
    "\"Psychology 1\": True,\n",
    "\"Psychology 110\": True,\n",
    "\"Psychology 114\": True,\n",
    "\"Psychology 130\": True,\n",
    "\"Psychology 135\": True,\n",
    "\"Psychology 160\": True,\n",
    "\"Psychology 167AC\": True,\n",
    "\"Psychology 198\": True,\n",
    "\"Psychology 290B\": True,\n",
    "\"Psychology C116\": True,\n",
    "\"Psychology W1\": True,\n",
    "\"Public Health 126\": False, # only Veterinary Preventive Medicine, Epidemiology, and Public Health and Health Engineering\n",
    "\"Public Health 142\": False,\n",
    "\"Public Health 150E\": False,\n",
    "\"Public Health 198\": False,\n",
    "\"Public Health W250B\": False,\n",
    "\"Public Policy 101\": False,\n",
    "\"Public Policy 157\": False,\n",
    "\"Public Policy 192AC\": False,\n",
    "\"Public Policy 198\": False,\n",
    "\"Public Policy C103\": False,\n",
    "\"Rhetoric R1B\": False,\n",
    "\"Scandinavian 106\": False,\n",
    "\"Slavic Languages & Lit R5B\": False,\n",
    "\"Social Welfare 112\": False,\n",
    "\"Social Welfare 114\": False,\n",
    "\"Sociology 1\": False,\n",
    "\"Sociology 127\": False,\n",
    "\"Sociology 140\": False,\n",
    "\"Sociology 167\": False,\n",
    "\"Sociology 198\": False,\n",
    "\"Sociology 3AC\": False,\n",
    "\"Southeast Asian 148\": False,\n",
    "\"Southeast Asian R5B\": False,\n",
    "\"Spanish 131\": False,\n",
    "\"Spanish 135\": False,\n",
    "\"Statistics 133\": True,\n",
    "\"Statistics 134\": True,\n",
    "\"Statistics 135\": True,\n",
    "\"Statistics 150\": True,\n",
    "\"Statistics 20\": True,\n",
    "\"Statistics 33B\": True,\n",
    "\"Statistics 88\": True,\n",
    "\"Statistics 89A\": True,\n",
    "\"Statistics C131A\": True,\n",
    "\"Statistics C140\": True,\n",
    "\"Theater Dance & Perf Stds 111\": False,\n",
    "\"Theater Dance & Perf Stds 172\": False,\n",
    "\"Theater Dance & Perf Stds 52AC\": False,\n",
    "\"Theater Dance & Perf Stds R1B\": False,\n",
    "\"UGIS-UG Interdisc Studies 192A\": False,\n",
    "\"UGIS-UG Interdisc Studies 192B\": False,\n",
    "\"UGIS-UG Interdisc Studies 192D\": False,\n",
    "\"UGIS-UG Interdisc Studies 192E\": False,\n",
    "\"UGIS-UG Interdisc Studies C122\": False\n",
    "}\n",
    "\n",
    "d_stem_courses = pd.DataFrame.from_dict(d_stem_courses, orient='index')\\\n",
    "    .reset_index()\\\n",
    "    .rename({'index': 'course_name_number', 0: 'is_stem_course'}, axis=1)\n",
    "\n",
    "d['survey_data'] = d['survey_data'].merge(d_stem_courses, on='course_name_number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but with majors\n",
    "d_stem_majors = {\n",
    "\"Anthropology\": False,\n",
    "\"Applied Mathematics\": True,\n",
    "\"Architecture\": False, \n",
    "\"Bioengineering\": True,\n",
    "\"Business Administration\": False,\n",
    "\"Chemical Engineering\": True,\n",
    "\"Chemistry\": True,\n",
    "\"Civil & Environmental Eng\": True,\n",
    "\"Civil Engineering\": True,\n",
    "\"Cognitive Science\": True,\n",
    "\"Computer Science\": True,\n",
    "\"Economics\": False,\n",
    "\"Electrical Eng & Comp Sci\": True,\n",
    "\"Engineering Physics\": True,\n",
    "\"English\": False,\n",
    "\"Environmental Sciences\": True,\n",
    "\"Gender & Womens Studies\": False,\n",
    "\"Global Studies\": False,\n",
    "\"Industrial Eng & Ops Rsch\": True,\n",
    "\"Integrative Biology\": True,\n",
    "\"L&S Computer Science\": True,\n",
    "\"L&S Data Science\": True,\n",
    "\"L&S Public Health\": False,\n",
    "\"L&S Social Welfare\": False,\n",
    "\"Letters & Sci Undeclared\": np.NaN,\n",
    "\"Linguistics\": False,\n",
    "\"MCB-Biochem & Mol Biol\": True,\n",
    "\"MCB-Cell & Dev Biology\": True,\n",
    "\"MCB-Genetics\": True,\n",
    "\"MCB-Neurobiology\": True,\n",
    "\"Mathematics\": True,\n",
    "\"Mechanical Engineering\": True,\n",
    "\"Media Studies\": False,\n",
    "\"Microbial Biology\": True,\n",
    "\"Molecular & Cell Biology\": True,\n",
    "\"Molecular Environ Biology\": True,\n",
    "\"Music\": False,\n",
    "\"Nut Sci-Physio & Metabol\": True,\n",
    "\"Nutritional Sci-Dietetics\": True,\n",
    "\"Nutritional Sci-Toxicology\": True,\n",
    "\"Nutritional Science\": True,\n",
    "\"Physics\": True,\n",
    "\"Political Economy\": False,\n",
    "\"Political Science\": False,\n",
    "\"Psychology\": True,\n",
    "\"Public Health\": False,\n",
    "\"Sociology\": False,\n",
    "\"Statistics\": True\n",
    "}\n",
    "\n",
    "d_stem_majors = pd.DataFrame.from_dict(d_stem_majors, orient='index')\\\n",
    "    .reset_index()\\\n",
    "    .rename({'index': 'major', 0: 'is_stem_student'}, axis=1)\n",
    "\n",
    "d['survey_data'] = d['survey_data'].merge(d_stem_majors, on='major', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General procedure: Write functions that create the variable for a specific combination of course_name_number and section names, return the variable for each combination, append the resulting vector of variable values to the original data frame of sampled courses and sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Course Variables from other Tables to Relevant Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join course_name_number and section_num to other tables\n",
    "# Note: Duplicate entries might emerge during joining\n",
    "canvas_courses = d['course_section'][\n",
    "    ['canvas_course_global_id', 'course_subject_name_number', 'section_num']\n",
    "]\n",
    "canvas_courses.columns = ['course_id', 'course_name_number', 'section_num']\n",
    "\n",
    "d['submissions'] = d['submissions'].merge(canvas_courses, on='course_id', how='left')\n",
    "d['submission_comments'] = d['submission_comments'].merge(canvas_courses, on='course_id', how='left')\n",
    "d['assignments'] = d['assignments'].merge(canvas_courses, on='course_id', how='left')\n",
    "d['assignments_with_due'] = d['assignments_with_due'].merge(canvas_courses, on='course_id', how='left')\n",
    "d['assignments_with_due-unlock'] = d['assignments_with_due-unlock'].merge(canvas_courses, on='course_id', how='left')\n",
    "d['discussion_entry'] = d['discussion_entry'].merge(canvas_courses, on='course_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['enrollments'] = d['enrollments'].merge(canvas_courses, on='course_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many students dropped out of the course in each 4 quarters of the Spring Semester (as a fraction of all originally enrolled students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dates for the Spring 2021 semester are January 18, 2021 to May 13, 2021.\n",
    "semester_start = pd.to_datetime('2021-01-18 00:00:00.000')\n",
    "semester_end = pd.to_datetime('2021-05-13 23:59:59.999')\n",
    "semester_quarter_limits = pd.date_range(semester_start, semester_end, periods=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take most recent enrollment state of each user in each course\n",
    "temp = d['enrollments'][['course_name_number', 'section_num', 'user_id', 'enrollment_updated_at', 'enrollment_state', 'enrollment_role_type']]\n",
    "temp = temp.sort_values(by=['enrollment_updated_at', 'course_name_number', 'section_num', 'user_id'], ascending=False)\n",
    "temp = temp.drop_duplicates(subset=['course_name_number', 'section_num', 'user_id'], keep='first', inplace=False)\n",
    "\n",
    "# Filter students\n",
    "temp = temp[temp['enrollment_role_type'] == 'StudentEnrollment']\n",
    "\n",
    "# If students dropped out before start of Spring Semester, do not impute Spring Semester start date\n",
    "# If students dropped out after end of Spring Semester, do not impute Spring Semester end date\n",
    "\n",
    "# Rather, remove students from the calculation which dropped out outside of the semester\n",
    "temp['enrollment_updated_at'] = pd.to_datetime(temp['enrollment_updated_at'])\n",
    "temp = temp[(temp.enrollment_updated_at >= semester_start) & (temp.enrollment_updated_at <= semester_end)]\n",
    "\n",
    "# Create \"dropped out in quarter n\" binary variables for each quarter\n",
    "temp['dropped_out_q1'] = (temp['enrollment_state'] == 'deleted') & (\n",
    "    semester_quarter_limits[0] <= temp['enrollment_updated_at']) & (\n",
    "    temp['enrollment_updated_at'] <= semester_quarter_limits[1])\n",
    "temp['dropped_out_q2'] = (temp['enrollment_state'] == 'deleted') & (\n",
    "    semester_quarter_limits[1] <= temp['enrollment_updated_at']) & (\n",
    "    temp['enrollment_updated_at'] <= semester_quarter_limits[2])\n",
    "temp['dropped_out_q3'] = (temp['enrollment_state'] == 'deleted') & (\n",
    "    semester_quarter_limits[2] <= temp['enrollment_updated_at']) & (\n",
    "    temp['enrollment_updated_at'] <= semester_quarter_limits[3])\n",
    "temp['dropped_out_q4'] = (temp['enrollment_state'] == 'deleted') & (\n",
    "    semester_quarter_limits[3] <= temp['enrollment_updated_at']) & (\n",
    "    temp['enrollment_updated_at'] <= semester_quarter_limits[4])\n",
    "\n",
    "temp_dropout_reference = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropped_out_ratio_q{1,2,3,4}\n",
    "def get_dropped_out_ratio(df, name1: str, section1: str, reference_var_quarter: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculates ratio of student dropout as a fraction of the total number of students that originally\n",
    "    enrolled in the course. \n",
    "    Please parse dropped_out_q{1,2,3,4} to variable 'reference_var_quarter'.\n",
    "    \"\"\"\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'] == section1)]\n",
    "    if temp.shape[0] == 0: # if no enrollment records are available, return NA\n",
    "        return np.nan\n",
    "    else:\n",
    "        return temp[temp[reference_var_quarter] == True].shape[0] / temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_ratio_q1 = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    dropout_ratio_q1.append(\n",
    "        get_dropped_out_ratio(temp_dropout_reference, \n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               'dropped_out_q1')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_ratio_q2 = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    dropout_ratio_q2.append(\n",
    "        get_dropped_out_ratio(temp_dropout_reference, \n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               'dropped_out_q2')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_ratio_q3 = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    dropout_ratio_q3.append(\n",
    "        get_dropped_out_ratio(temp_dropout_reference, \n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               'dropped_out_q3')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_ratio_q4 = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    dropout_ratio_q4.append(\n",
    "        get_dropped_out_ratio(temp_dropout_reference, \n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               'dropped_out_q4')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions to Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_comments_avg_size_bytes\n",
    "def get_submission_comments_avg_size_bytes(df, name1: str, section1: str, section2: list) -> float:\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1] + section2))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return 0\n",
    "    else:\n",
    "        all_submission_comments = temp\n",
    "        if all_submission_comments.shape[0] == 0: # if there are submission comments, we can not divide by 0\n",
    "            return 0 \n",
    "        else:\n",
    "            return sum(all_submission_comments.message_size_bytes) / all_submission_comments.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_comments_avg_size_bytes = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    submission_comments_avg_size_bytes.append(\n",
    "        get_submission_comments_avg_size_bytes(d['submission_comments'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   ast.literal_eval(row['secondary_section_number']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_comments_per_student(df, name1: str, section1: str, section2: list) -> float:\n",
    "    \"\"\"\n",
    "    Note: This function divides the number of submission comments made by TAs and teachers by the\n",
    "    number of students in a course, regardless of the dropout status of students.\n",
    "    \"\"\"\n",
    "    temp_comments = df['submission_comments'][(df['submission_comments']['course_name_number']==name1) & (df['submission_comments']['section_num'].isin([section1] + section2))]\n",
    "    temp_submission = df['submissions'][(df['submissions']['course_name_number']==name1) & (df['submissions']['section_num'].isin([section1] + section2))]\n",
    "    if temp_submission.shape[0] == 0: \n",
    "        return 0\n",
    "    else:\n",
    "        n_students_course = len(set(temp_submission[\n",
    "            (temp_submission.user_role == 'Student')\n",
    "        ].user_id))\n",
    "        if n_students_course == 0: # if no students are enrolled, we can not divide by 0\n",
    "            return 0\n",
    "        else:\n",
    "            all_submission_comments = temp_comments\n",
    "            return all_submission_comments.shape[0]/n_students_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_comments_per_student = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    submission_comments_per_student.append(\n",
    "        get_submission_comments_per_student(d, \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   ast.literal_eval(row['secondary_section_number']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percent_submissions_submission_comments(df, name1: str, section1: str, section2: list) -> float:\n",
    "    \"\"\"\n",
    "    Note: This function creates the intersection of submission IDs by students and submission comment\n",
    "    parents IDs and returns the ratio of submission IDs by students which received submission comments.\n",
    "    \"\"\"\n",
    "    temp_comments = df['submission_comments'][(df['submission_comments']['course_name_number']==name1) & (df['submission_comments']['section_num'].isin([section1] + section2))]\n",
    "    temp_submission = df['submissions'][(df['submissions']['course_name_number']==name1) & (df['submissions']['section_num'].isin([section1] + section2))]\n",
    "    if temp_submission.shape[0] == 0: \n",
    "        return np.nan\n",
    "    else:\n",
    "        # Get all submission IDs of submissions made by students that did not drop out\n",
    "        all_orig_student_submission_ids = set(pd.unique(temp_submission.submission_id).tolist())\n",
    "\n",
    "        # Get parent references from submission comments\n",
    "        all_parent_submission_comment_ids = set(pd.unique(temp_comments.submission_id).tolist())\n",
    "        \n",
    "        if len(all_orig_student_submission_ids) == 0: # can not divide by 0\n",
    "            return np.nan\n",
    "        else:\n",
    "            return len(all_orig_student_submission_ids & all_parent_submission_comment_ids) / len(all_orig_student_submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_submissions_submission_comments = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    percent_submissions_submission_comments.append(\n",
    "        get_percent_submissions_submission_comments(d,\n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   ast.literal_eval(row['secondary_section_number']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignments (number, spread, parallel, availability at beginning of semester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignment_spread(df, name1: str, section1: str, section2: list) -> float:\n",
    "    temp = df[(df.course_name_number==name1) & (df.section_num.isin([section1] + section2))]\n",
    "    if temp.shape[0] in [0, 1]: # standard deviation requires 2+ data points\n",
    "        return 0\n",
    "    else:\n",
    "        return temp.due_at_correct.astype(int).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_spread = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    assignment_spread.append(\n",
    "        get_assignment_spread(d['assignments_with_due'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel assignments\n",
    "## Current approach which adds a time period in front of assignment deadlines and counts pair-wise overlap ##\n",
    "\n",
    "# For all courses\n",
    "# 1. Create a timeframe for each assignment from deadline-1day to deadline\n",
    "# 2. Count number of timeframes that overlap in each course\n",
    "\n",
    "def check_overlap(tuple1, tuple2, i, j):\n",
    "    if i==j: # a timeframe will always overlap itself\n",
    "        return False\n",
    "    # this condition for overlap holds independent of which timeframe starts earlier\n",
    "    elif tuple1[0] < tuple2[1] and tuple2[0] < tuple1[1]:\n",
    "        return tuple(sorted([i, j])) # sort in order to filter out inverse later\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parallel_assingments(df, name1: str, section1: str, section2: list, grace_period_days: int) -> int:\n",
    "    temp = df[(df.course_name_number==name1) & (df.section_num.isin([section1] + section2))].copy()\n",
    "    if temp.shape[0] == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        temp['asn_frame_lag'] = d['assignments']['due_at_correct'] - timedelta(days=grace_period_days)\n",
    "        temp['asn_frame'] = list(zip(temp.asn_frame_lag, temp.due_at_correct))\n",
    "        out = []\n",
    "        for i, timeframe1 in enumerate(temp.asn_frame):\n",
    "            for j, timeframe2 in enumerate(temp.asn_frame):\n",
    "                out.append(check_overlap(timeframe1, timeframe2, i, j))\n",
    "        out = set([element for element in out if element != False and element is not None]) # casting to set drops inverse \n",
    "        return len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_assingments_1day = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    parallel_assingments_1day.append(\n",
    "        get_parallel_assingments(d['assignments_with_due'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']),\n",
    "                               grace_period_days=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_assingments_3day = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    parallel_assingments_3day.append(\n",
    "        get_parallel_assingments(d['assignments_with_due'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']),\n",
    "                               grace_period_days=3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flexible approach based on graded (3 days) or not graded (1 day)\n",
    "\n",
    "def timeframe_conditions(row):\n",
    "    res = 1 # 1 day, extend by factors and return value\n",
    "    if row['grading_type'] in ['points', 'percent', 'letter_grade', 'gpa_scale']:\n",
    "        res *= 3 \n",
    "    return row['due_at_correct'] - timedelta(days=res)\n",
    "\n",
    "def get_parallel_assingments_flexible(df, name1: str, section1: str, section2: list) -> int:\n",
    "    temp = df[(df.course_name_number==name1) & (df.section_num.isin([section1] + section2))].copy()\n",
    "    if temp.shape[0] == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        temp['asn_frame_start'] = temp.apply(timeframe_conditions, axis=1)\n",
    "        temp['asn_frame'] = list(zip(temp.asn_frame_start, temp.due_at_correct))\n",
    "        out = []\n",
    "        for i, timeframe1 in enumerate(temp.asn_frame):\n",
    "            for j, timeframe2 in enumerate(temp.asn_frame):\n",
    "                out.append(check_overlap(timeframe1, timeframe2, i, j))\n",
    "        out = set([element for element in out if element != False and element is not None]) # casting to set drops inverse \n",
    "        return len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_assingments_flexible = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    parallel_assingments_flexible.append(\n",
    "        get_parallel_assingments_flexible(d['assignments_with_due'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_course_assignments(df, name1: str, section1: str, section2: list, graded_only=False) -> int:\n",
    "    temp = df[(df.course_name_number==name1) & (df.section_num.isin([section1] + section2))]\n",
    "    if graded_only:\n",
    "        temp = temp[temp['grading_type'].isin(['points', 'percent', 'letter_grade', 'gpa_scale'])]\n",
    "    return 0 if temp.shape[0] == 0 else temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_course_assignments = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    n_course_assignments.append(\n",
    "        get_n_course_assignments(d['assignments'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']),\n",
    "                               graded_only=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_course_assignments_graded = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    n_course_assignments_graded.append(\n",
    "        get_n_course_assignments(d['assignments'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']),\n",
    "                               graded_only=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "semester_start = pd.to_datetime('2021-01-18 00:00:00.000')\n",
    "semester_end = pd.to_datetime('2021-05-13 23:59:59.999')\n",
    "\n",
    "weeks = []\n",
    "while semester_start <= semester_end:\n",
    "    weeks.append(semester_start)\n",
    "    semester_start += timedelta(days=7)\n",
    "    \n",
    "week_start_dates = weeks[:-1]\n",
    "week_end_dates = weeks[1:]\n",
    "\n",
    "def get_graded_assignments_week(df, name1: str, section1: str, section2: list, metric='average', \n",
    "                               week_start_dates=week_start_dates, week_end_dates=week_end_dates):\n",
    "    \"\"\"\n",
    "    Parse 'average' or 'max' as metric to get either the average number of graded assignments per week\n",
    "    or the maximum number of assignments during the whole semester which was due in a single calendar week.\n",
    "    \"\"\"\n",
    "    temp = df[(df.course_name_number==name1) & (df.section_num.isin([section1] + section2))]\n",
    "    temp = temp[temp['grading_type'].isin(['points', 'percent', 'letter_grade', 'gpa_scale'])]\n",
    "    \n",
    "    assignments_due_per_week_list = []\n",
    "    \n",
    "    for week_start, week_end in zip(week_start_dates, week_end_dates):\n",
    "        subset = temp[(temp['due_at_correct'] < week_end) & (week_start < temp['due_at_correct'])] # due this week only\n",
    "        assignments_due_per_week_list.append(subset.shape[0])\n",
    "\n",
    "    if metric == 'average':\n",
    "        return sum(assignments_due_per_week_list)/len(assignments_due_per_week_list)\n",
    "    elif metric == 'max':\n",
    "        return max(assignments_due_per_week_list)\n",
    "    else: raise ArgumentError('Please parse either \"average\" or \"max\" to argument \"metric\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_assignments_week_average = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    graded_assignments_week_average.append(\n",
    "        get_graded_assignments_week(d['assignments_with_due'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']),\n",
    "                               metric='average')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_assignments_week_max = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    graded_assignments_week_max.append(\n",
    "        get_graded_assignments_week(d['assignments_with_due'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']),\n",
    "                               metric='max')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_submission_time_to_deadline_minutes(df, name1: str, section1: str, section2: list, dropout_status=0) -> float:\n",
    "    temp_assignments = df['assignments_with_due'][(df['assignments_with_due'].course_name_number==name1) & (df['assignments_with_due']['section_num'].isin([section1] + section2))]\n",
    "    temp_submission = df['submissions'][(df['submissions'].course_name_number==name1) & (df['submissions']['section_num'].isin([section1] + section2))]\n",
    "    if temp_assignments.shape[0] == 0 or temp_submission.shape[0] == 0: \n",
    "        return 0\n",
    "    else:\n",
    "        # Join submission time of submissions table to respective assignment entry with due date\n",
    "        join_this = temp_submission[\n",
    "            (temp_submission.user_role == 'Student') &\n",
    "            (temp_submission.is_student_dropout == dropout_status) \n",
    "        ][['assignment_id', 'submitted_at']]\n",
    "        temp = pd.merge(temp_assignments[['course_id', 'assignment_id', 'due_at_correct']], \n",
    "                        join_this, on='assignment_id', how='left')\n",
    "\n",
    "        # Where possible, create average timeframe difference in minutes\n",
    "        temp['submitted_at'] = pd.to_datetime(temp['submitted_at']) \n",
    "        \n",
    "        temp['submission_diff'] = temp['due_at_correct'] - temp['submitted_at']\n",
    "        \n",
    "        return temp.submission_diff.dt.total_seconds().mean()/60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_submission_time_to_deadline_minutes = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    avg_submission_time_to_deadline_minutes.append(\n",
    "        get_avg_submission_time_to_deadline_minutes(d,\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "semester_start_plus_two_weeks = pd.to_datetime('2021-01-18 00:00:00.000') + timedelta(days=14)\n",
    "\n",
    "def get_early_assignment_availability_ratio(df, name1: str, section1: str, section2: list,\n",
    "                                            semester_start_plus_two_weeks=semester_start_plus_two_weeks) -> float:\n",
    "    temp = df[(df.course_name_number==name1) & (df.section_num.isin([section1] + section2))]\n",
    "    if temp.shape[0] == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return sum(temp['unlock_at_updated'] <= semester_start_plus_two_weeks) / temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_assignment_availability_ratio = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    early_assignment_availability_ratio.append(\n",
    "        get_early_assignment_availability_ratio(d['assignments_with_due-unlock'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_diff_available_due_assignments(df, name1: str, section1: str, section2: list) -> float:\n",
    "    temp = df[(df.course_name_number==name1) & (df.section_num.isin([section1] + section2))].copy()\n",
    "    if temp.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        temp['diff_available_due'] = temp['due_at_correct'] - temp['unlock_at_updated']\n",
    "        return temp.diff_available_due.dt.total_seconds().mean()/60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_diff_available_due_assignments = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    avg_diff_available_due_assignments.append(\n",
    "        get_avg_diff_available_due_assignments(d['assignments_with_due-unlock'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forum posts and TA responsivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_original_forum_posts(df, name1: str, section1: str, section2: str) -> int:\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return 0\n",
    "    else:\n",
    "        all_original_posts = temp[\n",
    "            (temp.depth == 1) & \n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == 0)]\n",
    "        return all_original_posts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_original_posts = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    n_original_posts.append(\n",
    "        get_n_original_forum_posts(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_original_forum_posts_dropout(df, name1: str, section1: str, section2: str) -> int:\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return 0\n",
    "    else:\n",
    "        all_original_posts = temp[\n",
    "            (temp.depth == 1) & \n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == 1)]\n",
    "        return all_original_posts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_original_posts_dropout = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    n_original_posts_dropout.append(\n",
    "        get_n_original_forum_posts_dropout(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_student_post_avg_size_bytes(df, name1: str, section1: str, section2: str) -> float:\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return 0\n",
    "    else:\n",
    "        all_original_posts = temp[\n",
    "            (temp.depth == 1) & \n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == 0)] \n",
    "        if all_original_posts.shape[0] == 0: # if there are no original posts by students, we can not divide by 0\n",
    "            return 0\n",
    "        else:\n",
    "            return sum(all_original_posts.message_length) / all_original_posts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_student_post_avg_size_bytes = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    original_student_post_avg_size_bytes.append(\n",
    "        get_original_student_post_avg_size_bytes(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_student_post_avg_size_bytes_dropout(df, name1: str, section1: str, section2: str) -> float:\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return 0\n",
    "    else:\n",
    "        all_original_posts = temp[\n",
    "            (temp.depth == 1) & \n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == 1)] \n",
    "        if all_original_posts.shape[0] == 0: # if there are no original posts by students, we can not divide by 0\n",
    "            return 0\n",
    "        else:\n",
    "            return sum(all_original_posts.message_length) / all_original_posts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_student_post_avg_size_bytes_dropout = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    original_student_post_avg_size_bytes_dropout.append(\n",
    "        get_original_student_post_avg_size_bytes_dropout(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_forum_posts_per_student(df, name1: str, section1: str, section2: list) -> float:\n",
    "    \"\"\"\n",
    "    Note: This function divides the number of original posts made by students that did not drop out\n",
    "    by the number of students that did not drop out and made at least one forum post (on all levels) in either \n",
    "    course section.\n",
    "    \"\"\"\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return 0\n",
    "    else:\n",
    "        n_students_course = len(set(temp[\n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == 0)\n",
    "        ].user_id))\n",
    "        if n_students_course == 0: # if no students participated in forum, we can not divide by 0\n",
    "            return 0\n",
    "        else :\n",
    "            all_original_posts = temp[\n",
    "                (temp.depth == 1) & \n",
    "                (temp.user_role == 'Student') &\n",
    "                (temp.is_student_dropout == 0)]\n",
    "            return all_original_posts.shape[0]/n_students_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_forum_posts_per_student = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    original_forum_posts_per_student.append(\n",
    "        get_original_forum_posts_per_student(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_forum_posts_per_student_dropout(df, name1: str, section1: str, section2: list) -> float:\n",
    "    \"\"\"\n",
    "    Note: This function divides the number of original posts made by students that did drop out\n",
    "    by the number of students that did drop out and made at least one forum post (on all levels) in either \n",
    "    course section.\n",
    "    \"\"\"\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return 0\n",
    "    else:\n",
    "        n_students_course = len(set(temp[\n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == 1)\n",
    "        ].user_id))\n",
    "        if n_students_course == 0: # if no students participated in forum, we can not divide by 0\n",
    "            return 0\n",
    "        else :\n",
    "            all_original_posts = temp[\n",
    "                (temp.depth == 1) & \n",
    "                (temp.user_role == 'Student') &\n",
    "                (temp.is_student_dropout == 1)]\n",
    "            return all_original_posts.shape[0]/n_students_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_forum_posts_per_student_dropout = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    original_forum_posts_per_student_dropout.append(\n",
    "        get_original_forum_posts_per_student_dropout(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ta_teacher_posts_per_student(df, name1: str, section1: str, section2: str) -> float:\n",
    "    \"\"\"\n",
    "    Note: This function divides the number of posts made by TAs or teachers\n",
    "    by the number of students (regardless of dropout status)  that made at least one forum post \n",
    "    (on all levels) in either course section.\n",
    "    \"\"\"\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return 0\n",
    "    else:\n",
    "        n_students_course = len(set(temp[\n",
    "            (temp.user_role == 'Student')\n",
    "        ].user_id))\n",
    "        if n_students_course == 0: # if no students participated in forum, we can not divide by 0\n",
    "            return 0\n",
    "        else :\n",
    "            all_original_teacher_posts = temp[temp.user_role.isin(['Ta', 'Teacher'])]\n",
    "            return all_original_teacher_posts.shape[0]/n_students_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_teacher_posts_per_student = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    ta_teacher_posts_per_student.append(\n",
    "        get_ta_teacher_posts_per_student(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ta_teacher_reply_time(df, name1: str, section1: str, section2: list) -> float:\n",
    "    \"\"\"\n",
    "    Note: This function returns the average reply time of TAs and teachers to posts by students \n",
    "    IF posts by students received a reply by a TA or teacher. Students are defined as students\n",
    "    that did not drop out. A separate variable for students who dropped out will be created.\n",
    "    \"\"\"\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return np.nan\n",
    "    else:\n",
    "        reference_ids = temp[\n",
    "            temp.depth != 1 & \n",
    "            temp.user_role.isin(['Ta', 'Teacher'])\n",
    "        ][['course_id', 'parent_discussion_entry_id', 'discussion_entry_id', 'created_at']]\n",
    "        \n",
    "        # Get posting dates of parent IDs, if they are posts by students and by non-dropouts\n",
    "        join_this = temp[\n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == 0)\n",
    "        ][['discussion_entry_id', 'created_at']]\n",
    "        \n",
    "        # If parent to teacher reply is a post by  student non-dropout, join creation date of parent post\n",
    "        diff = pd.merge(reference_ids, join_this, \n",
    "                 how='left', left_on=['parent_discussion_entry_id'], right_on=['discussion_entry_id'])\n",
    "        \n",
    "        # If parent is not such a post, an NA is joined, which is then omitted:\n",
    "        diff = diff.dropna()\n",
    "        \n",
    "        if diff.shape[0] == 0:  # if no instance of reply time is available for neither section, then return NA\n",
    "            return np.nan\n",
    "\n",
    "        else:\n",
    "            # Rename vars\n",
    "            del diff['discussion_entry_id_y'] # redundant, this is the parent ID from the ta/teacher reply\n",
    "            diff = diff.rename({'discussion_entry_id_x': 'discussion_entry_id', 'created_at_x': 'created_at_reply', \n",
    "                       'created_at_y': 'created_at_parent'}, axis=1)\n",
    "\n",
    "            diff['created_at_reply'] = pd.to_datetime(diff['created_at_reply'])\n",
    "            diff['created_at_parent'] = pd.to_datetime(diff['created_at_parent'])\n",
    "            diff['reply_time_minutes'] = diff.apply(lambda x: (x['created_at_reply']-x['created_at_parent']), axis=1)\n",
    "            \n",
    "            return diff['reply_time_minutes'].dt.total_seconds().mean()/60 # convert to minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_teacher_reply_time = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    ta_teacher_reply_time.append(\n",
    "        get_ta_teacher_reply_time(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ta_teacher_reply_time_dropout(df, name1: str, section1: str, section2: list) -> float:\n",
    "    \"\"\"\n",
    "    Note: This function returns the average reply time of TAs and teachers to posts by students \n",
    "    IF posts by students received a reply by a TA or teacher. Students are defined as students\n",
    "    that dropped out.\n",
    "    \"\"\"\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return np.nan\n",
    "    else:\n",
    "        reference_ids = temp[\n",
    "            temp.depth != 1 & \n",
    "            temp.user_role.isin(['Ta', 'Teacher'])\n",
    "        ][['course_id', 'parent_discussion_entry_id', 'discussion_entry_id', 'created_at']]\n",
    "        \n",
    "        # Get posting dates of parent IDs, if they are posts by students and by non-dropouts\n",
    "        join_this = temp[\n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == 1)\n",
    "        ][['discussion_entry_id', 'created_at']]\n",
    "        \n",
    "        # If parent to teacher reply is a post by  student non-dropout, join creation date of parent post\n",
    "        diff = pd.merge(reference_ids, join_this, \n",
    "                 how='left', left_on=['parent_discussion_entry_id'], right_on=['discussion_entry_id'])\n",
    "        \n",
    "        # If parent is not such a post, an NA is joined, which is then omitted:\n",
    "        diff = diff.dropna()\n",
    "        \n",
    "        if diff.shape[0] == 0:  # if no instance of reply time is available for neither section, then return NA\n",
    "            return np.nan\n",
    "\n",
    "        else:\n",
    "            # Rename vars\n",
    "            del diff['discussion_entry_id_y'] # redundant, this is the parent ID from the ta/teacher reply\n",
    "            diff = diff.rename({'discussion_entry_id_x': 'discussion_entry_id', 'created_at_x': 'created_at_reply', \n",
    "                       'created_at_y': 'created_at_parent'}, axis=1)\n",
    "\n",
    "            diff['created_at_reply'] = pd.to_datetime(diff['created_at_reply'])\n",
    "            diff['created_at_parent'] = pd.to_datetime(diff['created_at_parent'])\n",
    "            diff['reply_time_minutes'] = diff.apply(lambda x: (x['created_at_reply']-x['created_at_parent']), axis=1)\n",
    "            \n",
    "            return diff['reply_time_minutes'].dt.total_seconds().mean()/60 # gets actually converted to mins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_teacher_reply_time_dropout = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    ta_teacher_reply_time_dropout.append(\n",
    "        get_ta_teacher_reply_time_dropout(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply_ratio(df, name1: str, section1: str, section2: str) -> float:\n",
    "    \"\"\"\n",
    "    Note: This function returns the ratio of posts made by students that did not drop out\n",
    "    that received a reply by any user (TA/teacher/students*) which also includes replies\n",
    "    by students that dropped out because posts that already received a reply by these students\n",
    "    are less likely to receive another reply.\n",
    "    \"\"\"\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return np.nan\n",
    "    else:\n",
    "        all_orig_student_post_ids = set(temp[\n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == 0)\n",
    "        ].discussion_entry_id)\n",
    "        \n",
    "        if len(all_orig_student_post_ids) == 0: # if there are not posts made by students we can not divide by 0\n",
    "            return np.nan\n",
    "        else: \n",
    "            all_parent_post_ids = set(temp[\n",
    "                (temp.user_role.isin(['Student', 'Ta', 'Teacher']))\n",
    "            ].parent_discussion_entry_id)\n",
    "\n",
    "            # The intersection of post IDs and parent post IDs represent those student posts that received replies\n",
    "            return len(all_orig_student_post_ids & all_parent_post_ids)/len(all_orig_student_post_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_reply_ratio = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    forum_reply_ratio.append(\n",
    "        get_reply_ratio(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply_ratio_dropout(df, name1: str, section1: str, section2: str) -> float:\n",
    "    \"\"\"\n",
    "    Note: This function returns the ratio of posts made by students that did drop out\n",
    "    that received a reply by any user (TA/teacher/students*) which also includes replies\n",
    "    by students that did not drop out because posts that already received a reply by these students\n",
    "    are less likely to receive another reply.\n",
    "    \"\"\"\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no forum data available on neither section, return NA\n",
    "        return np.nan\n",
    "    else:\n",
    "        all_orig_student_post_ids = set(temp[\n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == 1)\n",
    "        ].discussion_entry_id)\n",
    "        \n",
    "        if len(all_orig_student_post_ids) == 0: # if there are not posts made by students we can not divide by 0\n",
    "            return np.nan\n",
    "        else: \n",
    "            all_parent_post_ids = set(temp[\n",
    "                (temp.depth != 1) & \n",
    "                (temp.user_role.isin(['Student', 'Ta', 'Teacher']))\n",
    "            ].parent_discussion_entry_id)\n",
    "\n",
    "            # The intersection of post IDs and parent post IDs represent those student posts that received replies\n",
    "            return len(all_orig_student_post_ids & all_parent_post_ids)/len(all_orig_student_post_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "forum_reply_ratio_dropout = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    forum_reply_ratio_dropout.append(\n",
    "        get_reply_ratio_dropout(d['discussion_entry'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Merging Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns to survey data\n",
    "dat = d['survey_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout Ratios\n",
    "dat['dropout_ratio_q1'] = dropout_ratio_q1\n",
    "dat['dropout_ratio_q2'] = dropout_ratio_q2\n",
    "dat['dropout_ratio_q3'] = dropout_ratio_q3\n",
    "dat['dropout_ratio_q4'] = dropout_ratio_q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignments, fix typos in object names\n",
    "dat['assignment_spread'] = assignment_spread\n",
    "dat['parallel_assignments_1day'] = parallel_assingments_1day\n",
    "dat['parallel_assignments_3day'] = parallel_assingments_3day\n",
    "dat['parallel_assignments_flexible'] = parallel_assingments_flexible\n",
    "dat['n_course_assignments'] = n_course_assignments\n",
    "dat['n_course_assignments_graded'] = n_course_assignments_graded\n",
    "dat['graded_assignments_week_average'] = graded_assignments_week_average\n",
    "dat['graded_assignments_week_max'] = graded_assignments_week_max\n",
    "dat['avg_submission_time_to_deadline_minutes'] = avg_submission_time_to_deadline_minutes\n",
    "dat['early_assignment_availability_ratio'] = early_assignment_availability_ratio\n",
    "dat['avg_diff_available_due_assignments'] = avg_diff_available_due_assignments\n",
    "\n",
    "# Submission Comments\n",
    "dat['submission_comments_avg_size_bytes'] = submission_comments_avg_size_bytes\n",
    "dat['submission_comments_per_student'] = submission_comments_per_student\n",
    "dat['percent_submissions_submission_comments'] = percent_submissions_submission_comments\n",
    "\n",
    "# Forum post quantity\n",
    "dat['n_original_posts'] = n_original_posts\n",
    "dat['n_original_posts_dropout'] = n_original_posts_dropout\n",
    "dat['original_student_post_avg_size_bytes'] = original_student_post_avg_size_bytes\n",
    "dat['original_student_post_avg_size_bytes_dropout'] = original_student_post_avg_size_bytes_dropout\n",
    "dat['original_forum_posts_per_student'] = original_forum_posts_per_student\n",
    "dat['original_forum_posts_per_student_dropout'] = original_forum_posts_per_student_dropout\n",
    "\n",
    "# Forum post responsivity\n",
    "dat['ta_teacher_posts_per_student'] = ta_teacher_posts_per_student\n",
    "dat['ta_teacher_reply_time'] = ta_teacher_reply_time\n",
    "dat['ta_teacher_reply_time_dropout'] = ta_teacher_reply_time_dropout\n",
    "dat['forum_reply_ratio'] = forum_reply_ratio\n",
    "dat['forum_reply_ratio_dropout'] = forum_reply_ratio_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variable\n",
    "dat['holds_secondary_sections'] = dat['secondary_section_number'] == '[]'\n",
    "dat.section_num = dat.section_num.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary control variables\n",
    "dat['students_did_not_use_forum'] = dat['n_original_posts'] == 0\n",
    "dat['teachers_ta_did_not_use_forum'] = dat['ta_teacher_posts_per_student'] == 0\n",
    "dat['course_did_not_use_submission_comments'] = dat['submission_comments_per_student'] == 0\n",
    "dat['course_did_not_use_assignments'] = dat['n_course_assignments'] == 0\n",
    "dat['students_dropout_did_not_use_forum'] = dat['n_original_posts_dropout'] == 0\n",
    "dat['course_did_not_use_forum'] = dat['students_did_not_use_forum'] & dat['teachers_ta_did_not_use_forum'] & dat['students_dropout_did_not_use_forum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_course_assignments_deadline_unlock(df, name1: str, section1: str, section2: list, graded_only=False) -> int:\n",
    "    \"\"\"\n",
    "    Returns the number of course assignments with deadlines or deadlines and unlock dates.\n",
    "    Used for control variable creation.\n",
    "    \"\"\"\n",
    "    temp = df[(df.course_name_number==name1) & (df.section_num.isin([section1] + section2))]\n",
    "    return temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_course_assignments_deadline = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    n_course_assignments_deadline.append(\n",
    "        get_n_course_assignments_deadline_unlock(d['assignments_with_due'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['course_did_not_use_assignments_with_deadlines'] = pd.Series(n_course_assignments_deadline) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_course_assignments_deadline_unlock = []\n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    n_course_assignments_deadline_unlock.append(\n",
    "        get_n_course_assignments_deadline_unlock(d['assignments_with_due-unlock'],\n",
    "                               row['course_name_number'], \n",
    "                               row['section_num'], \n",
    "                               ast.literal_eval(row['secondary_section_number']))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['course_did_not_use_assignments_with_deadlines_unlock'] = pd.Series(n_course_assignments_deadline_unlock) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_submissions_students(df, name1: str, section1: str, section2: str) -> float:\n",
    "    \"\"\"\n",
    "    This function returns the total number of submissions by students regardless of dropout\n",
    "    status to ascertain whether the submission feature was used in individual canvas courses\n",
    "    \"\"\"\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no submission data available on neither section, return 0\n",
    "        return 0\n",
    "    else:\n",
    "        all_submissions = temp[\n",
    "            (temp.user_role == 'Student')\n",
    "        ]\n",
    "        return all_submissions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_submissions_students = [] \n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    n_submissions_students.append(\n",
    "        get_n_submissions_students(d['submissions'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['course_did_not_use_submissions'] = pd.Series(n_submissions_students) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_submissions_students_by_dropout(df, name1: str, section1: str, section2: str, dropout_status=0) -> float:\n",
    "    \"\"\"\n",
    "    This function returns the total number of submissions by students by dropout\n",
    "    status to ascertain whether the submission feature was used in individual canvas courses.\n",
    "    \"\"\"\n",
    "    temp = df[(df['course_name_number']==name1) & (df['section_num'].isin([section1, section2]))]\n",
    "    if temp.shape[0] == 0: # if no submission data available on neither section, return 0\n",
    "        return 0\n",
    "    else:\n",
    "        all_submissions = temp[\n",
    "            (temp.user_role == 'Student') &\n",
    "            (temp.is_student_dropout == dropout_status)\n",
    "        ]\n",
    "        return all_submissions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_submissions_students_non_dropout = [] \n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    n_submissions_students_non_dropout.append(\n",
    "        get_n_submissions_students_by_dropout(d['submissions'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'],\n",
    "                                   dropout_status=0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['course_did_not_use_submissions_non_dropout'] = pd.Series(n_submissions_students_non_dropout) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_submissions_students_dropout = [] \n",
    "for index, row in survey_course_reference.iterrows():\n",
    "    n_submissions_students_dropout.append(\n",
    "        get_n_submissions_students_by_dropout(d['submissions'], \n",
    "                                   row['course_name_number'], \n",
    "                                   row['section_num'], \n",
    "                                   row['secondary_section_number'],\n",
    "                                   dropout_status=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['course_did_not_use_submissions_dropout'] = pd.Series(n_submissions_students_dropout) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "path = './aggregated_example_data/example_study_data.csv'\n",
    "dat.to_csv(path, index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
